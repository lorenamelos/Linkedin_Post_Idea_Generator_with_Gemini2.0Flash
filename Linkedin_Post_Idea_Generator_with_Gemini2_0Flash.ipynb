{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Nice Instagram Captions using Gemini 2.0 Flash"
      ],
      "metadata": {
        "id": "r4vGXgup1CcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, Iâ€™ll show you how to leverage the Gemini 2.0 Flash model (via the Generative AI API) to effortlessly generate multiple caption options for your Instagram posts.\n",
        "\n",
        "I know that probably there is an agent out there that does it. The intention here is to focus on those people who likes to someday CODE de agents and not just use them.\n",
        "\n",
        "I am a data scientist specializing in NLP, so my target here is to show how to use the API to build more personalized code, learning to tweak it to be just the way YOU want.\n",
        "\n",
        "---\n",
        "\n",
        "ğŸ‘‰ This is a very simple tutorial, just to show the basics on how to set up the Google's API and use Gemini 2.0 Flash â€” and any other Google's model available â€” so you can then build your own projects."
      ],
      "metadata": {
        "id": "qmJO8JUW1HB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph anthropic langchain_anthropic --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tstxhc6ZEa_s",
        "outputId": "60fc134f-7a75-417d-f276-ab9d54ba6e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m154.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETMlF8HHB0DY"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your actual Google API key\n",
        "GOOGLE_API_KEY = \"YOUR_GOOGLE_API_KEY\" # <<< --- REPLACE WITH YOUR KEY ---\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "fNAcLDZJEQ7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a state schema that holds a list of messages.\n",
        "class State(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "MYB3R3WME-SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a LangGraph instance with the state.\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# # --- LLM Initialization ---\n",
        "# Use a readily available model like gemini-1.5-flash or gemini-pro\n",
        "# Note: \"gemini-2.0-flash\" might not be available via the standard API yet.\n",
        "# Check Google AI documentation for the latest model names.\n",
        "\n",
        "try:\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not initialize gemini-1.5-flash. Trying gemini-pro. Error: {e}\")\n",
        "    try:\n",
        "        # Fallback option\n",
        "        model = genai.GenerativeModel(\"gemini-pro\")\n",
        "    except Exception as final_e:\n",
        "        print(f\"Error: Could not initialize any Gemini model. Please check your API key and model availability. Error: {final_e}\")\n",
        "        exit() # Exit if no model can be loaded\n",
        "\n",
        "\n",
        "# ------------------------- NODE FUNCTION -------------------------\n",
        "# Define the node function that generates post ideas\n",
        "def generate_post_ideas(state: State):\n",
        "    \"\"\"Generates LinkedIn post ideas based on the conversation history.\"\"\"\n",
        "    print(f\"\\n--- Entering generate_post_ideas ---\")\n",
        "    print(f\"Received state messages type: {type(state['messages'])}\")\n",
        "    print(f\"Received state messages content: {state['messages']}\")\n",
        "\n",
        "    # Convert LangChain message objects to the format Google API expects\n",
        "    # Google API expects a list of {'role': 'user'/'model', 'parts': [text]}\n",
        "    current_messages = state[\"messages\"]\n",
        "    history_for_google = []\n",
        "    for msg in current_messages:\n",
        "        role = 'user' if isinstance(msg, HumanMessage) else 'model'\n",
        "        # Ensure content is treated as text\n",
        "        content_text = str(msg.content)\n",
        "        history_for_google.append({'role': role, 'parts': [content_text]})\n",
        "\n",
        "    print(f\"Formatted history for Google API: {history_for_google}\")\n",
        "\n",
        "    # Define the number of post ideas\n",
        "    num_ideas = 5\n",
        "\n",
        "    # Construct a structured prompt for LinkedIn post ideas.\n",
        "    prompt_content = f\"\"\"Generate {num_ideas} creative and actionable LinkedIn post ideas focused on professional networking, considering the previous conversation context if any.\n",
        "                         Ensure each idea is concise and suitable for a LinkedIn post. Present the ideas in an enumerated format as follows:\n",
        "\n",
        "                         Suggestion 1: [LinkedIn Post Idea 1]\n",
        "                         Suggestion 2: [LinkedIn Post Idea 2]\n",
        "                         Suggestion 3: [LinkedIn Post Idea 3]\n",
        "                         Suggestion 4: [LinkedIn Post Idea 4]\n",
        "                         Suggestion 5: [LinkedIn Post Idea 5]\n",
        "                         \"\"\"\n",
        "\n",
        "    # The prompt itself is the user message for the API call\n",
        "    prompt_for_google = [{'role': 'user', 'parts': [prompt_content]}]\n",
        "\n",
        "    try:\n",
        "        # Use generate_content for stateless calls or if chat history management is simple\n",
        "        # Combine history and the new prompt\n",
        "        full_prompt_for_google = history_for_google + prompt_for_google\n",
        "\n",
        "        # Make the API call\n",
        "        response = model.generate_content(full_prompt_for_google)\n",
        "\n",
        "        # Debug: Print raw response\n",
        "        print(f\"Raw Google API response: {response}\")\n",
        "\n",
        "        # Extract text, handling potential errors or empty responses\n",
        "        if response.parts:\n",
        "            generated_text = response.text\n",
        "        else:\n",
        "            # Handle cases where the response might be blocked or empty\n",
        "            generated_text = \"Model did not generate a response. Check safety settings or prompt.\"\n",
        "            if hasattr(response, 'prompt_feedback'):\n",
        "                 generated_text += f\" (Feedback: {response.prompt_feedback})\"\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Google API call: {e}\")\n",
        "        # Handle API errors gracefully\n",
        "        generated_text = f\"An error occurred while generating ideas: {e}\"\n",
        "\n",
        "\n",
        "    print(f\"Generated text: {generated_text}\")\n",
        "    print(f\"--- Exiting generate_post_ideas ---\")\n",
        "\n",
        "    # Return the response as an AIMessage for LangGraph state\n",
        "    # Crucially, ensure the returned message is added back correctly by add_messages\n",
        "    return {\"messages\": [AIMessage(content=generated_text)]}\n",
        "\n"
      ],
      "metadata": {
        "id": "YLl20Ow3FTHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------- GRAPH CONSTRUCTION ------------------------- #\n",
        "\n",
        "# Adding the node to the graph\n",
        "graph_builder.add_node(\"post_idea_generator\", generate_post_ideas)\n",
        "\n",
        "# Define the graph flow\n",
        "graph_builder.add_edge(START, \"post_idea_generator\")\n",
        "graph_builder.add_edge(\"post_idea_generator\", END)\n",
        "\n",
        "# Compile the graph into a runnable object\n",
        "graph = graph_builder.compile()\n"
      ],
      "metadata": {
        "id": "IwYcpRudFTBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------- RUN THE AGENT ------------------------- #\n",
        "\n",
        "# --- Agent Runner ---\n",
        "def run_agent():\n",
        "    print(\"LinkedIn Post Ideas Generator. Type 'quit' to exit.\")\n",
        "    while True:\n",
        "        user_input = input(\"Enter some context or leave blank: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Exiting agent. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not user_input.strip():\n",
        "            print(\"No context provided, generating general networking ideas.\")\n",
        "            # Provide a minimal input if none is given, so the message list isn't empty\n",
        "            initial_message_content = \"General professional networking\"\n",
        "        else:\n",
        "            initial_message_content = user_input\n",
        "\n",
        "        # Initialize the state correctly for add_messages\n",
        "        # It expects a list containing message objects or dicts it can convert\n",
        "        initial_state = {\"messages\": [HumanMessage(content=initial_message_content)]}\n",
        "        # Alternative if the above causes issues (less likely with add_messages):\n",
        "        # initial_state = {\"messages\": [{\"role\": \"user\", \"content\": initial_message_content}]}\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Running Graph ---\")\n",
        "        print(f\"Initial State: {initial_state}\")\n",
        "\n",
        "        # Run the graph and stream the output\n",
        "        try:\n",
        "            for event in graph.stream(initial_state):\n",
        "                # Print the full event for debugging if needed\n",
        "                # print(f\"\\nGraph Event: {event}\")\n",
        "                for node_name, node_output in event.items():\n",
        "                    # Check if the output contains messages\n",
        "                    if isinstance(node_output, dict) and \"messages\" in node_output:\n",
        "                         # Get the last message added by the node\n",
        "                        last_message = node_output[\"messages\"][-1]\n",
        "                        # Ensure content is treated as string before printing\n",
        "                        print(f\"\\nAgent ({node_name}):\\n{str(last_message.content)}\")\n",
        "                    else:\n",
        "                        # Handle cases where the event might not be message output\n",
        "                        # print(f\"Event from {node_name}: {node_output}\")\n",
        "                        pass # Ignore non-message events for now\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n--- Error during graph execution ---\")\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc() # Print detailed traceback for debugging\n",
        "\n",
        "        print(f\"--- Graph Run Finished ---\")"
      ],
      "metadata": {
        "id": "WTGUdJAOJQ3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " run_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m7JropcmQoB-",
        "outputId": "c71a4c3a-3849-432d-d8f6-34775ab57068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinkedIn Post Ideas Generator. Type 'quit' to exit.\n",
            "Enter some context or leave blank: NATURAL LANGUAGE PROCESSING AND AI\n",
            "\n",
            "--- Running Graph ---\n",
            "Initial State: {'messages': [HumanMessage(content='NATURAL LANGUAGE PROCESSING AND AI', additional_kwargs={}, response_metadata={})]}\n",
            "\n",
            "--- Entering generate_post_ideas ---\n",
            "Received state messages type: <class 'list'>\n",
            "Received state messages content: [HumanMessage(content='NATURAL LANGUAGE PROCESSING AND AI', additional_kwargs={}, response_metadata={}, id='8cee91bc-2b9e-46af-b427-789fefee7ee3')]\n",
            "Formatted history for Google API: [{'role': 'user', 'parts': ['NATURAL LANGUAGE PROCESSING AND AI']}]\n",
            "Raw Google API response: response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"Suggestion 1: **Just finished an incredible NLP project leveraging AI to [mention specific application, e.g., improve customer sentiment analysis]. Connecting with fellow NLP/AI enthusiasts \\u2013 let's discuss the future of language models and where you see the biggest opportunities! #NLP #AI #MachineLearning #NaturalLanguageProcessing**\\n\\nSuggestion 2: **AI is transforming how we communicate. What's one NLP application you're most excited about in the business world? Share your thoughts below! \\ud83d\\udc47 I'm particularly interested in exploring [mention a specific area, e.g., the ethical implications of AI-powered content creation]. #AIinBusiness #NLPapplications #ArtificialIntelligence #FutureofWork**\\n\\nSuggestion 3: **Networking challenge: Connect with someone in NLP/AI you haven't spoken to before this week and learn about their work. Then, share one key takeaway in the comments. Let's expand our knowledge and network together! #NetworkingChallenge #AINetworking #NLPCommunity #ProfessionalGrowth**\\n\\nSuggestion 4: **Attending [Name of NLP/AI conference/webinar]? Let's connect beforehand! I'm looking forward to learning more about [mention specific topic related to the event]. Drop a comment if you'll be there too! #NLPConference #AIEvent #[EventHashtag] #MachineLearning**\\n\\nSuggestion 5: **Looking for collaborators on a project exploring [mention a specific NLP/AI project idea, e.g., using NLP for misinformation detection]. Open to researchers, developers, and anyone passionate about leveraging AI for good. Let's connect and brainstorm! #AIforGood #NLPproject #Collaboration #ArtificialIntelligence**\\n\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"avg_logprobs\": -0.5573628155482298\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 120,\n",
            "        \"candidates_token_count\": 346,\n",
            "        \"total_token_count\": 466\n",
            "      },\n",
            "      \"model_version\": \"gemini-2.0-flash\"\n",
            "    }),\n",
            ")\n",
            "Generated text: Suggestion 1: **Just finished an incredible NLP project leveraging AI to [mention specific application, e.g., improve customer sentiment analysis]. Connecting with fellow NLP/AI enthusiasts â€“ let's discuss the future of language models and where you see the biggest opportunities! #NLP #AI #MachineLearning #NaturalLanguageProcessing**\n",
            "\n",
            "Suggestion 2: **AI is transforming how we communicate. What's one NLP application you're most excited about in the business world? Share your thoughts below! ğŸ‘‡ I'm particularly interested in exploring [mention a specific area, e.g., the ethical implications of AI-powered content creation]. #AIinBusiness #NLPapplications #ArtificialIntelligence #FutureofWork**\n",
            "\n",
            "Suggestion 3: **Networking challenge: Connect with someone in NLP/AI you haven't spoken to before this week and learn about their work. Then, share one key takeaway in the comments. Let's expand our knowledge and network together! #NetworkingChallenge #AINetworking #NLPCommunity #ProfessionalGrowth**\n",
            "\n",
            "Suggestion 4: **Attending [Name of NLP/AI conference/webinar]? Let's connect beforehand! I'm looking forward to learning more about [mention specific topic related to the event]. Drop a comment if you'll be there too! #NLPConference #AIEvent #[EventHashtag] #MachineLearning**\n",
            "\n",
            "Suggestion 5: **Looking for collaborators on a project exploring [mention a specific NLP/AI project idea, e.g., using NLP for misinformation detection]. Open to researchers, developers, and anyone passionate about leveraging AI for good. Let's connect and brainstorm! #AIforGood #NLPproject #Collaboration #ArtificialIntelligence**\n",
            "\n",
            "--- Exiting generate_post_ideas ---\n",
            "\n",
            "Agent (post_idea_generator):\n",
            "Suggestion 1: **Just finished an incredible NLP project leveraging AI to [mention specific application, e.g., improve customer sentiment analysis]. Connecting with fellow NLP/AI enthusiasts â€“ let's discuss the future of language models and where you see the biggest opportunities! #NLP #AI #MachineLearning #NaturalLanguageProcessing**\n",
            "\n",
            "Suggestion 2: **AI is transforming how we communicate. What's one NLP application you're most excited about in the business world? Share your thoughts below! ğŸ‘‡ I'm particularly interested in exploring [mention a specific area, e.g., the ethical implications of AI-powered content creation]. #AIinBusiness #NLPapplications #ArtificialIntelligence #FutureofWork**\n",
            "\n",
            "Suggestion 3: **Networking challenge: Connect with someone in NLP/AI you haven't spoken to before this week and learn about their work. Then, share one key takeaway in the comments. Let's expand our knowledge and network together! #NetworkingChallenge #AINetworking #NLPCommunity #ProfessionalGrowth**\n",
            "\n",
            "Suggestion 4: **Attending [Name of NLP/AI conference/webinar]? Let's connect beforehand! I'm looking forward to learning more about [mention specific topic related to the event]. Drop a comment if you'll be there too! #NLPConference #AIEvent #[EventHashtag] #MachineLearning**\n",
            "\n",
            "Suggestion 5: **Looking for collaborators on a project exploring [mention a specific NLP/AI project idea, e.g., using NLP for misinformation detection]. Open to researchers, developers, and anyone passionate about leveraging AI for good. Let's connect and brainstorm! #AIforGood #NLPproject #Collaboration #ArtificialIntelligence**\n",
            "\n",
            "--- Graph Run Finished ---\n",
            "Enter some context or leave blank: QUIT\n",
            "Exiting agent. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}